\section{Introduction}\label{sec:introduction}

The marine pelagic environment, that is, the free water masses in the ocean, is the largest ecosystem on the planet (REF). The biomass in the pelagic is dominated by plankton (REF), which by definition are organisms that can not move against the current. Primary producers in the pelagic, phytoplankton, produce 50 \% of earth's oxygen, and are at the base of the food chain (REF). Small zooplankton, such as copepods, consume the phytoplankton and are food for higher consumers, like larvae of commercially important fish species.

To understand the ecosystem dynamics in the pelagic it is important to have good estimates of biomass and species composition of the plankton. However, traditional enumeration of plankton is a time-consuming process that requires extensive taxonomic expertise to differentiate the vast amount of plankton species. Recently, automated plankton imagers have become widespread to combat this issue. Instruments like the PlanktoScope \cite{pollina2022:planktoscope} can quantitatively image both phytoplankton and zooplankton. These instruments still require taxonomic knowledge to manually differentiate species, representing a major hurdle in high-throughput plankton quantification.

In recent years, as machine learning (ML) methods have become more advanced, the models have become more difficult to interpret. Decision trees are widely used as a supervised ML method because of their simple yet powerful nature, which makes them useful as baseline models when exploring more complex models. They can be utilized for both classification and regression problems, are non-parametric, and can provide insight by organizing the data in a tree structure. Decision trees can be improved through boosting methods, for example AdaBoost \cite{zou2009}.

Since their introduction in 1989 \cite{lecun1989}, convolutional neural networks (CNNs) have been widely used for image analysis, and successfully applied in, e.g., facial recognition, handwritten digit recognition, and medical imaging contexts \cite{li2022}. In contrast to the widespread fully-connected feed-forward neural networks (FCNNs), the architecture of CNNs are tailored for, e.g., image recognition tasks (see methods), and perform better in these contexts. 

Classification with both CNNs and decision trees are examples of supervised machine learning algorithms, where training of the network or tree depends on having pre-labeled data, that the algorithm then compares its output with. Unsupervised machine learning is an alternative to this, where the input data is sorted into clusters or groups without using pre-assigned labels \cite{olaode2014}. Unsupervised learning has been successfully applied to categorize biological data, including plankton \cite{pastore2023}.

In 2017, a novel architecture for deep learning was introduced with the infamous article "Attention is all you need" \cite{attention}. This architecture is today known as the transformer, and it formed the basis for the current AI wave which includes major names such as ChatGPT, Dal-E and AlphaFold 2. The transformer architecture was originally thought to replace recurrent neural networks (RNN) as the model of choice for translation of text. The model had several novel ways to train a network,
but the main focus was a new mechanism called "self-attention" (methods).

Only three years after the first transformer architecture was introduced, the article "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale" \cite{first_vit} introduced the first functional transformer trained on images, and it was baptized as a Vision Transformer (ViT). The authors demonstrate how a ViT outperforms classical deep learning methods such as CNN. 

A model named "self-distillation with no labels" (DINO) was introduced by Facebook (now Meta) shortly after the original ViT was proposed \cite{dino1}, as a self-supervised computer vision method inspired by the "Bootstrap your own latent"-method of self-supervision \cite{byol}. The authors found that DINO works exceptionally well with ViT architechtures, and their model achieved 80.1\% top-1 on ImageNet in linear evaluation. We use the second iteration of DINO, DINO v2 \cite{dino2} in the current study.

Here we apply several ML models to classify plankton image data from two different imagers. First, we apply a decision tree and AdaBoost to pre-extracted features from the data to investigate which classical features (length, width, opacity etc.) are most important for classification. Then, we train a CNN on the images and assess classification performance. Finally, we apply DINO v2 to extract features from the images, and use these features both directly for clustering, and as input for decision trees with and without AdaBoost. We compare the performance of all models, and discuss their applicability in plankton classification. We also discuss the potential of using unsupervised learning for pre-sorting large amounts of plankton data to streamline processing.